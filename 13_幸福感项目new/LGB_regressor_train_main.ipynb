{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline  ###管道流\n",
    "# from sklearn.neighbors import KNeighborsClassifier  #k近邻(knn)算法\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# 构建lgb模型\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings  #去除警告包\n",
    "warnings.filterwarnings('ignore')#去除警告\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 一般我们机器学习的流程\n",
    "\n",
    "# 一、加载数据\n",
    "#processs_datas/train_process_datas_x.csv\n",
    "datas_x = pd.read_csv('./processs_datas/train_process_datas_x.csv')\n",
    "# print(datas_x.head())\n",
    "# print(datas_x.info(verbose=True,null_counts=True))\n",
    "# processs_datas/train_datas_Y.csv\n",
    "datas_y = pd.read_csv('./processs_datas/train_datas_Y.csv')\n",
    "# print(datas_y.head())\n",
    "# print(datas_y.info())\n",
    "# print(datas_y['happiness'].value_counts())\n",
    "\n",
    "### 标签里面存在异常值 -8\n",
    "# ## 一般情况下对于标签存在异常的数据需要删除，注意对应的X也要删除\n",
    "# ## 先合并X,Y,再删除\n",
    "# datas = pd.concat([datas_x,datas_y],axis=1)\n",
    "# # print(datas.head())\n",
    "# # print(datas.info(verbose=True,null_counts=True))\n",
    "# datas.replace(-8,np.nan,inplace=True)\n",
    "# datas.dropna(axis=0,how='any',inplace=True)\n",
    "# # print(datas.shape)\n",
    "# # print(datas['happiness'].value_counts(dropna=True))\n",
    "\n",
    "## 这里我们可以考虑将-8替换成3（特殊情况特殊对待）\n",
    "datas_y.replace(-8,3,inplace=True)\n",
    "# print(datas_y.shape)\n",
    "# print(datas_y['happiness'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 二、数据清洗与预处理  （这里在dataprocess里面完成了）\n",
    "# 删除ID字段\n",
    "datas_x.drop(['id'],axis=1,inplace=True)\n",
    "\n",
    "# 三、获取数据的特征属性X和目标属性Y\n",
    "\n",
    "# 四、数据分割\n",
    "x_train,x_test,y_train,y_test = train_test_split(datas_x,datas_y,test_size=0.2,random_state=11)\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 五、特征工程  这里我们做个PCA降维 ## 使用管道流\n",
    "\n",
    "# # 六、模型构建\n",
    "# ##我们这里使用网格交叉验证,LGB回归（使用回归：评估指标是mse）\n",
    "# # # 网格调参\n",
    "# params ={\n",
    "#           'n_estimators': [400,700,1000],\n",
    "#           'max_depth':  [3, 5, 7],\n",
    "#           'num_leaves': [10,15,20],\n",
    "#           'subsample': [0.6, 0.8, 1.0],\n",
    "#           'colsample_bytree': [0.2,0.6,0.8],\n",
    "#           'learning_rate' : [0.01,0.02,0.03]\n",
    "# }\n",
    "\n",
    "# clf=GridSearchCV(estimator=LGBMRegressor(),param_grid=params,cv=3)\n",
    "\n",
    "# clf.fit(datas_x,datas_y)\n",
    "# print('最好的模型：',clf.best_estimator_)\n",
    "# print('最好模型的评分：',clf.best_score_)\n",
    "# print('最优参数：',clf.best_params_)\n",
    "# params_dir_path = './model'\n",
    "# import os\n",
    "# if os.path.exists(save_dir_path):\n",
    "#     pass\n",
    "# else:\n",
    "#     os.makedirs(save_dir_path)\n",
    "# with open('../model2/lgbparams.txt','w',encoding='utf-8') as file:\n",
    "#     file.write('最优参数：{} \\n 最好模型的评分：{}'.format(clf.best_params_,clf.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5368827699335841\n",
      "0.3283652097480225\n",
      "训练集mse为: 0.310856122802509\n",
      "测试集mse为: 0.4478292872702622\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=0.2,\n",
    "       importance_type='split', learning_rate=0.01, max_depth=5,\n",
    "       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
    "       n_estimators=1000, n_jobs=-1, num_leaves=20, objective=None,\n",
    "       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "       subsample=0.6, subsample_for_bin=200000, subsample_freq=0\n",
    "                     )\n",
    "\n",
    "\n",
    "lgb.fit(x_train,y_train)\n",
    "print(lgb.score(x_train,y_train))\n",
    "print(lgb.score(x_test,y_test))\n",
    "\n",
    "y_train_hat=lgb.predict(x_train)\n",
    "y_test_hat=lgb.predict(x_test)\n",
    "print('训练集mse为:',mean_squared_error(y_train,y_train_hat))\n",
    "print('测试集mse为:',mean_squared_error(y_test,y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5777518679410373\n",
      "0.2830481700352664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/lgb_happiness.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 九、模型持久化\n",
    "## 实际上对于最终我们保存的模型来说，我们可以把所有数据进行训练，再保存模型\n",
    "lgb = LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=0.2,\n",
    "              importance_type='split', learning_rate=0.02, max_depth=7,\n",
    "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
    "              n_estimators=700, n_jobs=-1, num_leaves=20, objective=None,\n",
    "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "              subsample=0.6, subsample_for_bin=200000, subsample_freq=0\n",
    "                     )\n",
    "lgb.fit(datas_x,datas_y)\n",
    "print(lgb.score(datas_x,datas_y))\n",
    "datas_y_hat = lgb.predict(datas_x)\n",
    "print(mean_squared_error(datas_y,datas_y_hat))\n",
    "import joblib\n",
    "\n",
    "save_dir_path = './model'\n",
    "import os\n",
    "if os.path.exists(save_dir_path):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(save_dir_path)\n",
    "\n",
    "joblib.dump(lgb,save_dir_path+'/lgb_happiness.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 22, 163, 332, 335,  79,  40,  53,  36,  68,  62, 208,  20, 248,\n",
       "         4,  12,  29,  39,  12,   0,   0,   0,  12, 182, 235, 222, 107,\n",
       "       304,  32,  61,  52,  38,  81, 101,  49,  45,  82,  38,  90,  48,\n",
       "        30,  91,  58, 117, 126,  18,  46,  41,  62, 109,  53, 171, 114,\n",
       "        67, 328, 207, 146, 189, 153,  73,  63,  92,  24,  42,  17,  34,\n",
       "        11,  10, 235, 145, 182, 130,  47,   2,  17,  18,   4,   2,   0,\n",
       "         0,   0,   0,  59,  93,  50,  80, 104,  28,  56, 165,  54,  47,\n",
       "        15,  55,  26,  94,  64,  61,  64,  86, 125, 137, 175, 199,  83,\n",
       "        79,  80, 103,  78,  89,  66,  85,  91, 100,  58,  94,  56, 179,\n",
       "       150, 149, 150, 199, 176, 200, 176, 226, 169,   0, 143,  88, 491,\n",
       "        20, 139, 172, 260, 124, 165, 155,  39])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
