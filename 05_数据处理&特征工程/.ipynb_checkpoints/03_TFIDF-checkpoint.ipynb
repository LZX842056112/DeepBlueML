{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1d86e1",
   "metadata": {},
   "source": [
    "# 词袋法&TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d68a7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46c0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = [\n",
    "    \"This is spark, spark sql a every good\",\n",
    "    \"Spark Hadoop Hbase\",\n",
    "    \"This is sample\",\n",
    "    \"This is anthor example anthor example\",\n",
    "    \"spark hbase hadoop spark hive hbase hue oozie\",\n",
    "    \"hue oozie spark\"\n",
    "]\n",
    "arr2 = [\n",
    "    \"this is a sample a example\",\n",
    "    \"this cd is another another sample example example\",\n",
    "    \"spark Hbase hadoop Spark hive hbase\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f032e311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 13)\t1.0\n",
      "  (0, 8)\t1.0\n",
      "  (0, 11)\t2.0\n",
      "  (0, 12)\t1.0\n",
      "  (0, 1)\t1.0\n",
      "  (0, 3)\t1.0\n",
      "  (1, 11)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 5)\t1.0\n",
      "  (2, 13)\t1.0\n",
      "  (2, 8)\t1.0\n",
      "  (2, 10)\t1.0\n",
      "  (3, 13)\t1.0\n",
      "  (3, 8)\t1.0\n",
      "  (3, 0)\t2.0\n",
      "  (3, 2)\t2.0\n",
      "  (4, 11)\t2.0\n",
      "  (4, 4)\t1.0\n",
      "  (4, 5)\t2.0\n",
      "  (4, 6)\t1.0\n",
      "  (4, 7)\t1.0\n",
      "  (4, 9)\t1.0\n",
      "  (5, 11)\t1.0\n",
      "  (5, 7)\t1.0\n",
      "  (5, 9)\t1.0\n",
      "[[0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 2. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      " [2. 0. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 2. 1. 1. 0. 1. 0. 2. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]]\n",
      "None\n",
      "['anthor' 'every' 'example' 'good' 'hadoop' 'hbase' 'hive' 'hue' 'is'\n",
      " 'oozie' 'sample' 'spark' 'sql' 'this']\n",
      "转换另外的文档数据\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 2. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 2. 1. 0. 0. 0. 0. 2. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 相当于词袋法\n",
    "count = CountVectorizer(min_df=0.1, dtype=np.float64, ngram_range=(0,1))\n",
    "df1 = count.fit_transform(arr1)\n",
    "print(df1)\n",
    "print (df1.toarray())\n",
    "print (count.get_stop_words())\n",
    "print (count.get_feature_names_out())\n",
    "print (\"转换另外的文档数据\")\n",
    "print (count.transform(arr2).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f41240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.43167582 0.         0.43167582 0.         0.\n",
      "  0.         0.         0.29885453 0.         0.         0.51219126\n",
      "  0.43167582 0.29885453]\n",
      " [0.         0.         0.         0.         0.62951441 0.62951441\n",
      "  0.         0.         0.         0.         0.         0.4554374\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.49468646 0.         0.71454223 0.\n",
      "  0.         0.49468646]\n",
      " [0.66820557 0.         0.66820557 0.         0.         0.\n",
      "  0.         0.         0.23130351 0.         0.         0.\n",
      "  0.         0.23130351]\n",
      " [0.         0.         0.         0.         0.30742585 0.61485171\n",
      "  0.37490304 0.30742585 0.         0.30742585 0.         0.44482931\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.62951441 0.         0.62951441 0.         0.4554374\n",
      "  0.         0.        ]]\n",
      "转换另外的文档数据\n",
      "[[0.         0.         0.58137639 0.         0.         0.\n",
      "  0.         0.         0.40249409 0.         0.58137639 0.\n",
      "  0.         0.40249409]\n",
      " [0.         0.         0.81932864 0.         0.         0.\n",
      "  0.         0.         0.2836157  0.         0.40966432 0.\n",
      "  0.         0.2836157 ]\n",
      " [0.         0.         0.         0.         0.34137811 0.68275622\n",
      "  0.4163075  0.         0.         0.         0.         0.49395647\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 基于TF的值(词袋法)，做一个IDF的转换\n",
    "tfidf_t = TfidfTransformer()\n",
    "df2 = tfidf_t.fit_transform(df1)\n",
    "print (df2.toarray())\n",
    "print (\"转换另外的文档数据\")\n",
    "print (tfidf_t.transform(count.transform(arr2)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0768750f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.43167582 0.         0.43167582 0.         0.\n",
      "  0.         0.         0.29885453 0.         0.         0.51219126\n",
      "  0.43167582 0.29885453]\n",
      " [0.         0.         0.         0.         0.62951441 0.62951441\n",
      "  0.         0.         0.         0.         0.         0.4554374\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.49468646 0.         0.71454223 0.\n",
      "  0.         0.49468646]\n",
      " [0.66820557 0.         0.66820557 0.         0.         0.\n",
      "  0.         0.         0.23130351 0.         0.         0.\n",
      "  0.         0.23130351]\n",
      " [0.         0.         0.         0.         0.30742585 0.61485171\n",
      "  0.37490304 0.30742585 0.         0.30742585 0.         0.44482931\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.62951441 0.         0.62951441 0.         0.4554374\n",
      "  0.         0.        ]]\n",
      "['anthor', 'every', 'example', 'good', 'hadoop', 'hbase', 'hive', 'hue', 'is', 'oozie', 'sample', 'spark', 'sql', 'this']\n",
      "None\n",
      "转换另外的文档数据\n",
      "[[0.         0.         0.58137639 0.         0.         0.\n",
      "  0.         0.         0.40249409 0.         0.58137639 0.\n",
      "  0.         0.40249409]\n",
      " [0.         0.         0.81932864 0.         0.         0.\n",
      "  0.         0.         0.2836157  0.         0.40966432 0.\n",
      "  0.         0.2836157 ]\n",
      " [0.         0.         0.         0.         0.34137811 0.68275622\n",
      "  0.4163075  0.         0.         0.         0.         0.49395647\n",
      "  0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lq\\.conda\\envs\\py37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## 相当TF+IDF(先做词袋法再做IDF转换)\n",
    "tfidf_v = TfidfVectorizer(min_df=0, dtype=np.float64)\n",
    "df3 = tfidf_v.fit_transform(arr1)\n",
    "print (df3.toarray())\n",
    "print (tfidf_v.get_feature_names())\n",
    "print (tfidf_v.get_stop_words())\n",
    "print (\"转换另外的文档数据\")\n",
    "print (tfidf_v.transform(arr2).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6da65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
